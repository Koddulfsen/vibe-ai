#!/usr/bin/env python3
"""
Enhanced Master Agent with Complete Solution Engine Integration
"""

import os
import sys
import json
import argparse
from typing import Dict, List, Any, Optional
from datetime import datetime
import subprocess

# Add current directory to path for imports
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

from verification_layer import VerificationLayer
from complete_solution_implementation import (
    CompleteSolutionEngine, 
    DeepUnderstandingEngine,
    HolisticProjectAnalyzer,
    IntelligentGapBridger
)

class EnhancedMasterAgent:
    """Master Agent with Complete Solution capabilities"""
    
    def __init__(self):
        self.verification_layer = VerificationLayer()
        self.solution_engine = CompleteSolutionEngine()
        self.understanding_engine = DeepUnderstandingEngine()
        self.gap_bridger = IntelligentGapBridger()
        
    def execute_complete_solution(self, user_input: str, 
                                output_dir: Optional[str] = None) -> Dict[str, Any]:
        """Execute complete solution generation"""
        print("\nüöÄ Enhanced vibe.ai Complete Solution Engine")
        print("=" * 60)
        
        # Create complete solution
        solution = self.solution_engine.create_complete_solution(user_input)
        
        # Generate actual files
        if output_dir:
            self._generate_solution_files(solution, output_dir)
        
        # Create summary report
        report = self._create_solution_report(solution)
        
        return {
            "success": solution.deployment_ready,
            "solution": solution,
            "report": report,
            "output_directory": output_dir
        }
    
    def _generate_solution_files(self, solution, output_dir: str):
        """Generate actual solution files"""
        os.makedirs(output_dir, exist_ok=True)
        
        # Create project structure
        print("\nüìÅ Generating project structure...")
        
        # Generate based on architecture
        if solution.blueprint.architecture["style"] == "microservices":
            self._generate_microservices_structure(solution, output_dir)
        else:
            self._generate_monolithic_structure(solution, output_dir)
        
        # Generate documentation
        self._generate_documentation_files(solution, output_dir)
        
        # Generate deployment files
        self._generate_deployment_files(solution, output_dir)
        
        print(f"‚úÖ Generated complete solution in: {output_dir}")
    
    def _generate_microservices_structure(self, solution, output_dir: str):
        """Generate microservices project structure"""
        services = ["api-gateway", "auth-service", "product-service", 
                   "order-service", "payment-service"]
        
        for service in services:
            service_dir = os.path.join(output_dir, "services", service)
            os.makedirs(os.path.join(service_dir, "src"), exist_ok=True)
            os.makedirs(os.path.join(service_dir, "tests"), exist_ok=True)
            
            # Generate main.py
            main_content = self._generate_service_main(service, solution)
            with open(os.path.join(service_dir, "src", "main.py"), 'w') as f:
                f.write(main_content)
            
            # Generate Dockerfile
            dockerfile_content = self._generate_dockerfile(service, solution)
            with open(os.path.join(service_dir, "Dockerfile"), 'w') as f:
                f.write(dockerfile_content)
            
            # Generate requirements.txt
            requirements = self._generate_requirements(service, solution)
            with open(os.path.join(service_dir, "requirements.txt"), 'w') as f:
                f.write(requirements)
    
    def _generate_service_main(self, service: str, solution) -> str:
        """Generate main.py for a service"""
        tech = solution.blueprint.architecture["technologies"].get("backend", "fastapi")
        
        if tech == "fastapi":
            return f'''"""
{service.replace("-", " ").title()} Service
Auto-generated by vibe.ai Complete Solution Engine
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from prometheus_fastapi_instrumentator import Instrumentator
import uvicorn
import os
from typing import Optional

# Import verification layer
from verification_layer import VerificationLayer

app = FastAPI(
    title="{service.replace("-", " ").title()}",
    description="Auto-generated service with zero-hallucination verification",
    version="1.0.0"
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Add Prometheus metrics
Instrumentator().instrument(app).expose(app)

# Initialize verification layer
verifier = VerificationLayer()

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {{
        "status": "healthy",
        "service": "{service}",
        "timestamp": datetime.utcnow().isoformat()
    }}

@app.get("/readiness")
async def readiness_check():
    """Readiness check endpoint"""
    # Add actual readiness checks here
    return {{"ready": True}}

# Add service-specific routes here based on the service type
{self._generate_service_routes(service)}

if __name__ == "__main__":
    port = int(os.getenv("PORT", 8000))
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=port,
        reload=os.getenv("ENVIRONMENT", "production") == "development"
    )
'''
        else:
            # Generate for other frameworks
            return f"# {service} main file for {tech}"
    
    def _generate_service_routes(self, service: str) -> str:
        """Generate service-specific routes"""
        routes = {
            "auth-service": '''
@app.post("/register")
async def register(user_data: dict):
    """User registration endpoint"""
    # Verify input data
    verification = verifier.verify_output("auth-service", {
        "action": "register",
        "data": user_data
    })
    
    if verification["verification_status"] != "verified":
        raise HTTPException(status_code=400, detail="Invalid input data")
    
    # Implementation here
    return {"message": "User registered successfully"}

@app.post("/login")
async def login(credentials: dict):
    """User login endpoint"""
    # Implementation here
    return {"access_token": "...", "token_type": "bearer"}
''',
            "product-service": '''
@app.get("/products")
async def list_products(skip: int = 0, limit: int = 100):
    """List products with pagination"""
    # Implementation here
    return {"products": [], "total": 0}

@app.post("/products")
async def create_product(product: dict):
    """Create a new product"""
    # Verify product data
    verification = verifier.verify_output("product-service", {
        "action": "create_product",
        "data": product
    })
    
    if verification["verification_status"] != "verified":
        raise HTTPException(status_code=400, detail="Invalid product data")
    
    # Implementation here
    return {"id": "...", "message": "Product created"}
''',
            "order-service": '''
@app.post("/orders")
async def create_order(order_data: dict):
    """Create a new order"""
    # Implementation here
    return {"order_id": "...", "status": "pending"}

@app.get("/orders/{order_id}")
async def get_order(order_id: str):
    """Get order details"""
    # Implementation here
    return {"order_id": order_id, "status": "...", "items": []}
'''
        }
        
        return routes.get(service, "# Add service-specific routes here")
    
    def _generate_dockerfile(self, service: str, solution) -> str:
        """Generate Dockerfile for a service"""
        tech = solution.blueprint.architecture["technologies"].get("backend", "python")
        
        if "python" in tech.lower() or "fastapi" in tech.lower():
            return f'''FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \\
    gcc \\
    && rm -rf /var/lib/apt/lists/*

# Copy requirements
COPY requirements.txt .

# Install Python dependencies
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY src/ ./src/

# Create non-root user
RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=40s --retries=3 \\
    CMD python -c "import requests; requests.get('http://localhost:8000/health')"

# Run the application
CMD ["python", "-m", "src.main"]
'''
        else:
            # Generate for other languages
            return f"# Dockerfile for {tech}"
    
    def _generate_requirements(self, service: str, solution) -> str:
        """Generate requirements.txt for a service"""
        base_requirements = [
            "fastapi==0.104.1",
            "uvicorn[standard]==0.24.0",
            "pydantic==2.5.0",
            "python-dotenv==1.0.0",
            "prometheus-fastapi-instrumentator==6.1.0",
            "httpx==0.25.2",
            "sqlalchemy==2.0.23",
            "alembic==1.12.1",
            "python-jose[cryptography]==3.3.0",
            "passlib[bcrypt]==1.7.4",
            "python-multipart==0.0.6",
        ]
        
        service_specific = {
            "auth-service": [
                "python-jose[cryptography]==3.3.0",
                "passlib[bcrypt]==1.7.4",
                "email-validator==2.1.0",
            ],
            "product-service": [
                "elasticsearch==8.11.0",
                "redis==5.0.1",
            ],
            "payment-service": [
                "stripe==7.8.0",
            ],
            "recommendation-service": [
                "tensorflow==2.15.0",
                "scikit-learn==1.3.2",
                "pandas==2.1.4",
                "numpy==1.24.3",
            ]
        }
        
        requirements = base_requirements + service_specific.get(service, [])
        return "\n".join(sorted(set(requirements)))
    
    def _generate_monolithic_structure(self, solution, output_dir: str):
        """Generate monolithic project structure"""
        # Create directories
        dirs = [
            "src/api", "src/models", "src/services", "src/utils",
            "tests/unit", "tests/integration", "tests/e2e",
            "config", "scripts", "docs"
        ]
        
        for dir_path in dirs:
            os.makedirs(os.path.join(output_dir, dir_path), exist_ok=True)
        
        # Generate main application file
        main_content = self._generate_monolithic_main(solution)
        with open(os.path.join(output_dir, "src", "main.py"), 'w') as f:
            f.write(main_content)
    
    def _generate_monolithic_main(self, solution) -> str:
        """Generate main.py for monolithic app"""
        return '''"""
Main Application
Auto-generated by vibe.ai Complete Solution Engine
"""

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from prometheus_fastapi_instrumentator import Instrumentator
import uvicorn
import os

# Import routers
from api import auth_router, product_router, order_router

# Import verification layer
from verification_layer import VerificationLayer

app = FastAPI(
    title="Complete Solution API",
    description="Auto-generated API with zero-hallucination verification",
    version="1.0.0"
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Add Prometheus metrics
Instrumentator().instrument(app).expose(app)

# Initialize verification layer
verifier = VerificationLayer()

# Include routers
app.include_router(auth_router, prefix="/api/v1/auth", tags=["auth"])
app.include_router(product_router, prefix="/api/v1/products", tags=["products"])
app.include_router(order_router, prefix="/api/v1/orders", tags=["orders"])

@app.get("/")
async def root():
    """Root endpoint"""
    return {
        "message": "Complete Solution API",
        "version": "1.0.0",
        "docs": "/docs"
    }

if __name__ == "__main__":
    port = int(os.getenv("PORT", 8000))
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=port,
        reload=os.getenv("ENVIRONMENT", "production") == "development"
    )
'''
    
    def _generate_documentation_files(self, solution, output_dir: str):
        """Generate documentation files"""
        docs_dir = os.path.join(output_dir, "docs")
        os.makedirs(docs_dir, exist_ok=True)
        
        # Generate README
        with open(os.path.join(output_dir, "README.md"), 'w') as f:
            f.write(solution.documentation["readme"])
        
        # Generate API docs
        with open(os.path.join(docs_dir, "api.md"), 'w') as f:
            f.write(solution.documentation["api_docs"])
        
        # Generate architecture docs
        with open(os.path.join(docs_dir, "architecture.md"), 'w') as f:
            f.write(solution.documentation["architecture_docs"])
    
    def _generate_deployment_files(self, solution, output_dir: str):
        """Generate deployment configuration files"""
        # Docker Compose
        docker_compose = self._generate_docker_compose(solution)
        with open(os.path.join(output_dir, "docker-compose.yml"), 'w') as f:
            f.write(docker_compose)
        
        # Kubernetes manifests
        if solution.blueprint.deployment_strategy["platform"] == "kubernetes":
            k8s_dir = os.path.join(output_dir, "k8s")
            os.makedirs(k8s_dir, exist_ok=True)
            
            # Generate deployment manifest
            deployment = self._generate_k8s_deployment(solution)
            with open(os.path.join(k8s_dir, "deployment.yaml"), 'w') as f:
                f.write(deployment)
    
    def _generate_docker_compose(self, solution) -> str:
        """Generate docker-compose.yml"""
        return '''version: '3.8'

services:
  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: app_db
      POSTGRES_USER: app_user
      POSTGRES_PASSWORD: secure_password
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U app_user"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  app:
    build: .
    ports:
      - "8000:8000"
    environment:
      DATABASE_URL: postgresql://app_user:secure_password@postgres:5432/app_db
      REDIS_URL: redis://redis:6379
      ENVIRONMENT: development
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - ./src:/app/src
    command: python -m src.main

volumes:
  postgres_data:
'''
    
    def _generate_k8s_deployment(self, solution) -> str:
        """Generate Kubernetes deployment manifest"""
        return '''apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-deployment
  labels:
    app: complete-solution
spec:
  replicas: 3
  selector:
    matchLabels:
      app: complete-solution
  template:
    metadata:
      labels:
        app: complete-solution
    spec:
      containers:
      - name: app
        image: complete-solution:latest
        ports:
        - containerPort: 8000
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: database-url
        - name: REDIS_URL
          valueFrom:
            configMapKeyRef:
              name: app-config
              key: redis-url
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /readiness
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
---
apiVersion: v1
kind: Service
metadata:
  name: app-service
spec:
  selector:
    app: complete-solution
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8000
  type: LoadBalancer
'''
    
    def _create_solution_report(self, solution) -> Dict[str, Any]:
        """Create comprehensive solution report"""
        return {
            "summary": {
                "name": solution.blueprint.name,
                "deployment_ready": solution.deployment_ready,
                "architecture": solution.blueprint.architecture["style"],
                "technologies": solution.blueprint.architecture["technologies"]
            },
            "requirements": {
                "explicit": len(solution.blueprint.understanding.explicit_requirements),
                "implicit": len(solution.blueprint.understanding.implicit_requirements),
                "security": len(solution.blueprint.understanding.security_requirements)
            },
            "implementation": {
                "files_generated": len(solution.implementation.get("code_generated", [])),
                "tests_written": len(solution.implementation.get("tests_written", [])),
                "configs_created": len(solution.implementation.get("configs_created", []))
            },
            "verification": solution.verification,
            "next_steps": self._generate_next_steps(solution)
        }
    
    def _generate_next_steps(self, solution) -> List[str]:
        """Generate next steps for the user"""
        steps = []
        
        if solution.deployment_ready:
            steps.extend([
                "Run 'docker-compose up' to start development environment",
                "Access API documentation at http://localhost:8000/docs",
                "Run tests with 'pytest' command",
                "Deploy to production using './scripts/deploy.sh'"
            ])
        else:
            steps.extend([
                "Review and address verification failures",
                "Complete any manual gap bridging required",
                "Run verification again",
                "Then proceed with deployment"
            ])
        
        return steps


def main():
    parser = argparse.ArgumentParser(
        description="Enhanced vibe.ai Master Agent with Complete Solution Engine"
    )
    
    subparsers = parser.add_subparsers(dest="command", help="Commands")
    
    # Complete solution command
    solution_parser = subparsers.add_parser(
        "create",
        help="Create a complete solution from description"
    )
    solution_parser.add_argument(
        "description",
        help="Natural language description of what to build"
    )
    solution_parser.add_argument(
        "--output",
        "-o",
        default="./generated-solution",
        help="Output directory for generated solution"
    )
    solution_parser.add_argument(
        "--verify-only",
        action="store_true",
        help="Only verify without generating files"
    )
    
    # Legacy workflow command (backwards compatible)
    workflow_parser = subparsers.add_parser(
        "workflow",
        help="Run traditional agent workflow"
    )
    workflow_parser.add_argument(
        "--type",
        choices=["full-dev", "planning", "execute", "quality"],
        default="full-dev",
        help="Workflow type"
    )
    workflow_parser.add_argument(
        "--tag",
        help="Task tag"
    )
    
    args = parser.parse_args()
    
    if args.command == "create":
        # Use Complete Solution Engine
        agent = EnhancedMasterAgent()
        
        # Create complete solution
        result = agent.execute_complete_solution(
            args.description,
            None if args.verify_only else args.output
        )
        
        # Display report
        print("\nüìä Solution Report")
        print("=" * 60)
        print(json.dumps(result["report"], indent=2))
        
        if result["success"]:
            print("\n‚úÖ Solution created successfully!")
            if not args.verify_only:
                print(f"üìÅ Output directory: {args.output}")
                print("\nüöÄ Next Steps:")
                for i, step in enumerate(result["report"]["next_steps"], 1):
                    print(f"   {i}. {step}")
        else:
            print("\n‚ùå Solution creation failed. Check the report for details.")
    
    elif args.command == "workflow":
        # Run legacy workflow for backwards compatibility
        print("Running legacy workflow...")
        # Implementation of legacy workflow
    
    else:
        parser.print_help()


if __name__ == "__main__":
    main()